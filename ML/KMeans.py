#!/usr/bin/env python
# -*- coding: utf-8 -*-
# K-means (Duda & Hart) #
# sampleSpace -> Conjunto de puntos a agrupar
# classes -> Número de clases para la agrupación
# clusters -> Conjunto de clusters donde acumular los refinamientos 
from random import randint
from sys import maxint

# Distribución cíclica de muestras entre clusters (probar con otras inicializaciones a ver si converge más rápido con otras) #
def generate_random_clusters(clusters,classes,sampleSpace):
	for n in xrange(len(sampleSpace)):
		clusters[n%len(classes)].append(sampleSpace[n])
	return clusters

# K-Means #
def kmeans(clusters,classes,sampleSpace,max_iter,verbose):
	representatives = [[] for n in xrange(len(classes))]
	J,count_iter,transfers = 0,0,False
	for c in xrange(len(classes)):
		sumx = [0 for i in xrange(len(sampleSpace[0]))]
		for x in clusters[c]: sumx = vectorsum(x,sumx)
		representatives[c] = vectorxconstant(sumx,(1.0/len(clusters[c])))
	if verbose : print "Representantes: " + str(representatives)
	while(not transfers and count_iter < max_iter):
		count_iter,transfers = (count_iter+1),False
		# Por cada muestra i del espacio muestral #
		for sample in sampleSpace:
			# Conocer cluster de i (Prefijo i -> indice) #
			iclusteri = get_sample_cluster(clusters,sample)
			if len(clusters[iclusteri]) > 1:
				icluster_optimum = None; auxMin = maxint; aux = None; VJ = 0
				# Calcular ( argmin\_j!=i nj / (nj+1) * ||x-mj||^2 / ) que minimize el SEC de esa muestra #
				for iclusterj in xrange(len(clusters)):
					if iclusterj != iclusteri:
						aux = vectorpow2(vectorabs(vectordifference(sample,representatives[iclusterj])))*(len(clusters[iclusterj])/len(clusters[iclusterj])+1.0)
						if(aux<auxMin):
							auxMin = aux
							icluster_optimum = iclusterj
				if verbose : print "Sample " + str(sample) + " mas cerca de " + str(representatives[icluster_optimum]) + " con SEC " + str(auxMin)
				# Calcular gradiente de J #
				VJ = vectorpow2(vectorabs(vectordifference(sample,representatives[icluster_optimum])))*(len(clusters[icluster_optimum])/len(clusters[icluster_optimum])+1.0) - float((vectorpow2(vectorabs(vectordifference(sample,representatives[iclusteri])))*(len(clusters[iclusteri]))/len(clusters[iclusteri])-1.0))
				# Si el SEC se reduce cambiando la muestra de un cluster a otro, cambiar #
				if(VJ<0):
					transfers = True
					if verbose : print "Sample movida del cluster: " + str(iclusteri) + " al cluster: " + str(icluster_optimum)
					# Recalcular representantes #
					representatives[iclusteri]        = vectordifference(representatives[iclusteri],(vectordconstant(vectordifference(sample,representatives[iclusteri]),(len(clusters[iclusteri])-1.0))))
					representatives[icluster_optimum] = vectorsum(representatives[icluster_optimum],(vectordconstant(vectordifference(sample,representatives[icluster_optimum]),(len(clusters[icluster_optimum])-1.0))))
					# Transferencia de la muestra #
					clusters[iclusteri].remove(sample)
					clusters[icluster_optimum].append(sample)
					J += VJ
	return [clusters,representatives,J]
	
## Funciones vectores ##
def vectorxvector(v,y):
	s = 0
	for n in xrange(len(v)):
		s += v[n] * y[n]
	return s
	
def vectordconstant(v,a):
	return [x/a for x in v]
	
def vectorxconstant(v,a):
	return [x*a for x in v]

def vectordifference(v,y):
	return [v[n]-y[n] for n in xrange(len(v))]

def vectorsum(v,y):
	return [v[n]+y[n] for n in xrange(len(v))]	

def vectorabs(v):
	return [abs(i) for i in v]	

def vectorpow2(v):
	return vectorxvector(v,v)

# Funciones k-means #
def get_sample_cluster(clusters,sample):
	for icluster in xrange(len(clusters)):
		for point in clusters[icluster]:
			if point == sample: return icluster
	return -1

def genera_espacio_muestral_aleatorio(n,inf,sup):
	return [[randint(inf,sup),randint(inf,sup)] for x in xrange(n)]

def classify(train_samples,test_samples):
	classes     = ["Malware","NoMalware"]
	clusters    = [[],[]]
	clusters    = generate_random_clusters(clusters,classes,train_samples)
	(clusters,representatives,J) = kmeans(clusters,classes,train_samples,10000,False) 
	res = []
	for test_sample in test_samples: res.append(get_sample_cluster(clusters,test_sample))
	return res

def __str__(): return "Kmeans classifier"
## EntryPoint ##	
if __name__ == '__main__':
	# Test #
	sampleSpace = [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]# || genera_espacio_muestral_aleatorio(30,1,30)
	print classify(sampleSpace,[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]# || genera_espacio_muestral_aleatorio(30,1,30)
)
	
